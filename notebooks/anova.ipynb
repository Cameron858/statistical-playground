{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from scipy.stats import levene, f_oneway, f\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# ANOVA: Analysis of Variance\n",
    "\n",
    "This notebook demonstrates how to perform and interpret Analysis of Variance (ANOVA) tests using real-world datasets. It covers:\n",
    "- Formulating hypothesese\n",
    "- Validating assumptions\n",
    "- Interpreting results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Analysis of Variance (ANOVA) is a statistical test used to determine whether there are any statistically significant differences between the means of two or more independent groups. Rather than comparing group means directly, ANOVA analyzes the variation:\n",
    "- Within groups (how much individual values vary inside each group)\n",
    "- Between groups (how much the group means vary from each other)\n",
    "\n",
    "By comparing these sources of variance, ANOVA helps us determine whether the observed differences in group means are likely due to real effects or just random noise.\n",
    "\n",
    "This comparison is summarised in the F-statistic, which is the ratio of variance between groups to variance within groups. \n",
    "\n",
    "$$ F = \\frac{Var(Between\\ groups)}{Var(Within\\ groups)} $$\n",
    "\n",
    "Intuitively, if the between-group variance is large relative to the within-group variance, it suggests that the group means differ beyond what could be expected by chance.\n",
    "\n",
    "The F-statistic follows an F-distribution, which depends on the degrees of freedom associated with the number of groups and the sample sizes. Understanding the shape of the F-distribution helps us decide how extreme an observed F-statistic must be to indicate significant differences.\n",
    "\n",
    "Below, we visualise several F-distributions with varying degrees of freedom to illustrate how the distribution changes and what critical values might look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pairs = [(1, 10), (2, 20), (5, 50), (10, 100), (3, 175)]\n",
    "x = np.linspace(0, 5, 500)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.ylim((0, 2))\n",
    "\n",
    "for dfn, dfd in df_pairs:\n",
    "    y = f.pdf(x, dfn, dfd)\n",
    "    plt.plot(x, y, label=f'df1={dfn}, df2={dfd}')\n",
    "\n",
    "plt.title('F-distributions with different degrees of freedom')\n",
    "plt.xlabel('F value')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## ANVOA\n",
    "\n",
    "We will use the `wines` dataset. The target is cultivator a wine was produced by. We will examine if there is any difference in `alcohol` between the cultivators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_wine(as_frame=True)\n",
    "df = dataset.frame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "Examine the number of samples for each `target` value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"target\")[\"alcohol\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Let's create boxplots to visualise the spread of `alcohol` for each of the different cultivators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.boxplot(column=\"alcohol\", by=\"target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "From the above plot it is clear that wines from cultivator `1` have on average a lower `alcohol` value, and also more extreme values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "The degree of the differences observed above suggest that they are statistically significant. This is a good scenario for using an ANOVA test. We can formulate the above problem as thus:\n",
    "\n",
    "**Hypothesis**\n",
    "- $ H_0: \\mu_0 = \\mu_1 = \\mu_2 $ (All means are equal)\n",
    "- $ H_a: \\text{At least one } \\mu_i \\neq \\mu_j \\text{ for some } i \\neq j $ (At least one mean is different from the rest)\n",
    "\n",
    "We shall use an alpha value of 0.05.\n",
    "$$ alpha = 0.05 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_0 = df[df[\"target\"] == 0][\"alcohol\"]\n",
    "group_1 = df[df[\"target\"] == 1][\"alcohol\"]\n",
    "group_2 = df[df[\"target\"] == 2][\"alcohol\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Before we perform the hypothesis testing, it is important to highlight some key assumptions:\n",
    "1. **Independence**\n",
    "    - Observations must be independant of one another.\n",
    "    - For the `wine` dataset, provided the data was collected following proper sampling procedures (e.g., different bottles, vineyards, or production batches), this assumption is reasonable. However, if there were any repeated measurements or dependencies in the sampling process, this assumption could be violated.\n",
    "3. **Normality**\n",
    "    - The target values within each group (`alcohol` in this case) should be roughly normally distributed. However, since each group has a sufficient number of observations (~60), the Central Limit Theorem implies that the distribution of the sample means will be approximately normal, even if the original data deviates somewhat from normality.\n",
    "5. **Homoscedacity**\n",
    "    - Both groups have a similar variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Validating Assumptions\n",
    "\n",
    "We will test the assumptions above. Since the assumptions for ANOVA are very similar to those for t-tests, these examples will be less detailed. For a more comprehensive use case, please refer to [T-tests](./t_tests.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "#### Independence\n",
    "\n",
    "As stated above, this assumption is reasonably satisfied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "#### Normality\n",
    "\n",
    "To check the normality assumption, we will use Q-Q plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(10, 4))\n",
    "\n",
    "stats.probplot(group_0, dist=\"norm\", plot=axs[0])\n",
    "axs[0].set_title(\"Cultivar 0\")\n",
    "\n",
    "stats.probplot(group_1, dist=\"norm\", plot=axs[1])\n",
    "axs[1].set_title(\"Cultivar 1\")\n",
    "\n",
    "stats.probplot(group_2, dist=\"norm\", plot=axs[2])\n",
    "axs[2].set_title(\"Cultivar 2\")\n",
    "\n",
    "fig.suptitle(\"Q-Q Plots\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "Normality observations:\n",
    "- In general, the data follows the 45 degree line, indicating normality\n",
    "- Cultivar `1` appears to show the most deviance from the 45 degree line. This behaviour is more extreme at the higher end (~2), suggesting slight departure from normality\n",
    "\n",
    "From the above plots, it is safe to assume that the normality assumption holds for all 3 groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "#### Homoscedacity\n",
    "\n",
    "We have implicitly performed a visual insepction of homoscedacity above when examining the boxplots. Hence in this section, we shall only perform a Levene test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "levene_stat, levene_p_stat = levene(group_0, group_1, group_2)\n",
    "print(f\"Levene's test statistic: {levene_stat:.4f}\")\n",
    "print(f\"p-value: {levene_p_stat:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "Levene's Observations:\n",
    "- A Levene’s test statistic value of 0.5998 indicates that the variance differences between the groups are small relative to the variability within each group. This suggests the groups have similar variances.\n",
    "- A p-value of 0.5501 is larger than our alpha of 0.05, so we fail to reject the null hypothesis of equal variances.\n",
    "\n",
    "The assumption of homoscedacity holds for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "#### Validating Assumptions - Conclusion\n",
    "\n",
    "Considering the above results, all key assumptions have been reasonably met: independence, normality (supported by the Q-Q plots), and homoscedasticity (confirmed by Levene’s test). This supports the validity of the test conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "### Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "We shall now use `scipy` to perform a two-tailed t-test. Scipy's `f_oneway` returns two values:\n",
    "1. `t-statistic`: How far the sample means are, relative to the variability in the data (larger = more significance)\n",
    "2. `pvalue`: Probability in oberserving a difference at least as large as the one seen in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_stat, p_value = f_oneway(group_0, group_1, group_2)\n",
    "\n",
    "print(f\"F-statistic: {f_stat:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "Considering the above results:\n",
    "- An *f-statistic* value of: 135.0776 suggests that the variance between the group means is much larger than the variance within the groups. This is strong evidence that at least one group mean differs significantly.\n",
    "- A *p-value* of < 0.0001 is much smaller than our alpha of 0.05\n",
    "\n",
    "In conclusion, based on the above ANOVA test, we **reject** the **null** hypothesis and conclude that there is statistically significant evidence to suggest that the mean alcohol content differs between at least two of the cultivar groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "We can visualise this by plotting the F-distribution along with our F-statistic value. Due to the very large value (~135), we shall only plot $ \\pm 1\\% $ either side of it (This can be changed using the `perc` variable in the code block bellow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "\n",
    "# n groups - 1\n",
    "df_between = 2\n",
    "# n samples - n groups\n",
    "df_within = len(df) - 3\n",
    "\n",
    "perc = 0.01\n",
    "x_min = f_stat * (1 - perc)\n",
    "x_max = f_stat * (1 + perc)\n",
    "\n",
    "# F-distribution PDF\n",
    "x = np.linspace(x_min, x_max, 1000)\n",
    "y = f.pdf(x, df_between, df_within)\n",
    "\n",
    "# Critical F-value for rejection region (right tail)\n",
    "f_crit = f.ppf(1 - alpha, df_between, df_within)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(x, y, label=f'F-distribution df1={df_between}, df2={df_within}')\n",
    "plt.fill_between(x, 0, y, where=(x >= f_crit), color='red', alpha=0.3, label='Rejection region (α=0.05)')\n",
    "plt.axvline(f_stat, color='black', linestyle='--', label='Observed F-statistic = 135.08')\n",
    "\n",
    "plt.title('F-distribution with Rejection Region for ANOVA')\n",
    "plt.xlabel('F value')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated the use of ANOVA to test for differences in the mean `alcohol` content across three different wine cultivars.\n",
    "\n",
    "- The key assumptions of ANOVA independence, normality, and equal variances, were validated through Q-Q plots and Levene’s test.\n",
    "- The ANOVA F-statistic and corresponding p-value provided strong evidence to reject the null hypothesis that the means of the groups are equal.\n",
    "- This indicates that at least one wine cultivar differs significantly in its mean alcohol content compared to the others.\n",
    "\n",
    "Mastering ANOVA builds a solid foundation for analyzing differences across multiple groups and can be extended to more complex experimental designs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
