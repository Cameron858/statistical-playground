{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from scipy.stats import norm, t, levene, ttest_ind\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# T-tests: one-tailed and two-tailed examples\n",
    "\n",
    "This notebook demonstrates how to perform and interpret both one-tailed and two-tailed t-tests using real-world datasets. It covers:\n",
    "\n",
    "- Formulating hypotheses\n",
    "- Validating assumptions (normality, independence, equal variances)\n",
    "- Performing Welch’s t-test when variances differ\n",
    "- Interpreting results with p-values and confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The t-distribution is a probability distribution that resembles the normal distribution but has heavier tails. This means it accounts for greater uncertainty, especially with small sample sizes or when the population variance is unknown. As the sample size (degrees of freedom) increases, the t-distribution approaches the normal distribution.\n",
    "\n",
    "t-test's can be used to determine if there is a significant difference between the means of two groups. It is useful when the population standard deviation is unknown and the sample size is small. The t-test relies on the t-distribution to calculate the probability (p-value) of observing the data assuming the null hypothesis is true.\n",
    "\n",
    "The plot below compares the standard normal distribution (in blue) with t-distributions for 3 degrees of freedom (red dashed) and 10 degrees of freedom (green dotted):\n",
    "- The t-distribution with 3 degrees of freedom has noticeably heavier tails than the normal distribution. This reflects increased uncertainty due to the smaller sample size.\n",
    "- The t-distribution with 10 degrees of freedom is closer to the normal curve, illustrating how the t-distribution converges to the normal as sample size grows.\n",
    "- These heavier tails mean that extreme values are more probable under the t-distribution, making it more conservative when sample sizes are small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = np.linspace(-4, 4, 1000)\n",
    "\n",
    "# normal\n",
    "normal_pdf = norm.pdf(x, 0, 1)\n",
    "\n",
    "# t-distributions with different degrees of freedom\n",
    "t_dof1 = t.pdf(x, df=1)\n",
    "t_dof3 = t.pdf(x, df=3)\n",
    "t_dof10 = t.pdf(x, df=10)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "plt.plot(x, normal_pdf, label='Normal (df=inf)', color='blue')\n",
    "plt.plot(x, t_dof1, label='t-distribution (df=1)', color='orange', linestyle='--')\n",
    "plt.plot(x, t_dof3, label='t-distribution (df=3)', color='red', linestyle='-.')\n",
    "plt.plot(x, t_dof10, label='t-distribution (df=10)', color='green', linestyle=':')\n",
    "\n",
    "plt.title('Normal vs t-distributions')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## One tailed t-test\n",
    "\n",
    "We will use `diabetes` for an example. The target is a \"quantitative measure of disease progression one year after baseline\" We will examine if there is a difference in the target based of off `sex`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_diabetes(as_frame=True, scaled=False)\n",
    "df = dataset.frame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "Let's create a boxplot to show the difference in the target by `sex`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.boxplot(column=\"target\", by=\"sex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Both boxes are very similar, however the box for sex `1` looks like it has slightly lower values (As seen by Q1 and Q3). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "Out of curisoity, let's see some simple stats for each `sex` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"sex\")[\"target\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "The table above does show that the mean for sex `1` is slightly lower than sex `0`. This raises, the question, is this difference statistically significant?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "We now have two groups, in which we want to check that the mean in one is **strictly lower** than the mean in the other. This is a perfect scenario for using a **one tailed t-test** to verify this. We can formulate the above problem thus:\n",
    "\n",
    "**Hypotheses**\n",
    "- $ H_0: \\mu_1 \\geq \\mu_2 $ (Group 1 has the same or higher average `target` value)\n",
    "- $ H_a: \\mu_1 < \\mu_2 $ (Group 1 has a lower average `target` value)\n",
    "\n",
    "We shall use an alpha value of 0.05 to determine significance, as it represents a 5% risk of concluding that a difference exists when there is none (Type I error). This is a commonly accepted threshold in hypothesis testing\n",
    "\n",
    "$$ alpha = 0.05 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Create the groups for each `sex` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_1 = df[df[\"sex\"] == 1][\"target\"]\n",
    "group_2 = df[df[\"sex\"] == 2][\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "Before we perform the hypothesis testing, it is important to highlight some key assumptions:\n",
    "1. **Independence**\n",
    "    - Observations must be independant of one another. This assumption is reasonably satisfied with this dataset as each observation represents a unique individual. \n",
    "3. **Normality**\n",
    "    - The target values within each group (`target` column in this case) should be approximately normally distributed. Since each group contains 200+ observations (as seen above), the *Central Limit Theorem* suggests that the sampling distribution of the mean will be approximately normal, even if the underlying data is not perfectly normal.\n",
    "5. **Homoscedacity**\n",
    "    - Both groups have a similar variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### Validating Assumptions\n",
    "\n",
    "For completeness, the above assumptions will be tested."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "#### Independence\n",
    "\n",
    "As stated above, this assumption is reasonably satisfied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "#### Normality\n",
    "\n",
    "There are many methods of validating the normality of groups. For this example, we shall use a **Q-Q plot** (quantile-quantile plot). A Q-Q plot compares the quantiles of the sample data against the quantiles of a standard normal distribution. If the data is normally distributed, the points will approximately lie on a straight 45 degree line.\n",
    "\n",
    "Interpretation:\n",
    "- Points on the line -> data follows a normal distribution\n",
    "- Points curving away at the ends -> heavy tails (kurtosis) or skew\n",
    "- Systematic upward or downward bends -> skewness (left or right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "stats.probplot(group_1, dist=\"norm\", plot=axs[0])\n",
    "axs[0].set_title(\"Q-Q Plot: Sex 1\")\n",
    "\n",
    "stats.probplot(group_2, dist=\"norm\", plot=axs[1])\n",
    "axs[1].set_title(\"Q-Q Plot: Sex 2\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "Normality Observations:\n",
    "\n",
    "- In general, the data points follow the straight 45 degree line, indicating approximate normality.\n",
    "- Towards the lower end (~ -3), the points curve upwards away from the line. However, since this pattern is subtle and consistent across both groups, it likely does not meaningfully violate the normality assumption—especially considering the sample size and the robustness of the t-test.\n",
    "\n",
    "Ideally, we would like to see a closer adherence to the 45 degree line throughout. However, for the purpose of this example, we can accept that the normality assumption is reasonably met."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "#### Homoscedacity\n",
    "\n",
    "Homoscedacity can be tested via visual inspection, or using statistical tests. We shall perform one of each:\n",
    "1. Boxplot inspection\n",
    "2. Levene test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "**Boxplot Inspection**\n",
    "  \n",
    "Firstly, we return to the boxplot plotted previously to perform a visual inspection of the variance between the groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.boxplot(column=\"target\", by=\"sex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "Boxplot Observations:\n",
    "- The IQR for sex `1` is slightly smaller than for sex `2`, indicating a somewhat tighter concentration of middle 50% values in sex `1`.\n",
    "- The range represented by the whiskers for sex `1` is slightly larger than sex `2`, suggesting that while the core data spread is tighter, the overall spread (including potential outliers) is wider."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "**Levene's Test**\n",
    "\n",
    "The Levene test tests the null hypothesis that all samples are from populations with equal variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "levene_stat, levene_p_stat = levene(group_1, group_2)\n",
    "print(f\"Levene's test statistic: {levene_stat:.4f}\")\n",
    "print(f\"p-value: {levene_p_stat:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "Levene's Observations:\n",
    "- A Levene’s test statistic value of 0.6426 indicates that the variance differences between the groups are small relative to the variability within each group. This suggests the groups have similar variances.\n",
    "- A p-value of 0.4232 is larger than our alpha of 0.05, so we fail to reject the null hypothesis of equal variances.\n",
    "\n",
    "The assumption of homoscedacity holds for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "#### Validating Assumptions - Conclusion\n",
    "\n",
    "Considering the above results, all key assumptions have been reasonably met: independence, normality (supported by the Q-Q plots), and homoscedasticity (confirmed by boxplot inspection and Levene’s test). This supports the validity of the test conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "### Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "We shall now use `scipy` to perform a two-tailed t-test. Scipy's `ttest_ind` returns two values:\n",
    "1. `t-statistic`: How far the sample means are, relative to the variability in the data (larger = more significance)\n",
    "2. `pvalue`: Probability in oberserving a difference at least as large as the one seen in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# equal_var=False performs Welch's t-test which is more robust to different population variances \n",
    "result = ttest_ind(group_2, group_1, equal_var=False)\n",
    "t_stat, p_two_tailed, df = result.statistic, result.pvalue, result.df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "As we want to perform a one-tailed t-test, we need to divide the `p` value by two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "if t_stat > 0:\n",
    "    # t in the expected direction (group1 < group2)\n",
    "    p_one_tailed = p_two_tailed / 2\n",
    "else:\n",
    "    p_one_tailed = 1 - (p_two_tailed / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "We can now examine the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"t-statistic: {t_stat:.4f}\")\n",
    "print(f\"One-tailed p-value: {p_one_tailed:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "Considering the above results:\n",
    "- A *t-statistic* value of 0.9022 suggests that the groups means are less than 1 standard error apart. This is not strong evidence that there is a difference.\n",
    "- A *p-value* of 0.1837 is larger than our alpha of 0.05\n",
    "\n",
    "In conclusion, based off of the above one-tailed t-test we **fail** to reject the **null** hypothesis as there is insignificant evidence to conclude that a sex of `1` results in a lower `target` value than a sex of `2`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "We can visually represent the one-tailed t-test results. The curve shows the t-distribution with the degrees of freedom calculated from our data.\n",
    "\n",
    "- The red shaded area on the left tail represents the rejection region for our test at the chosen significance level (alpha=0.05). As our alternative hypothesis is that Group 1’s mean is less than Group 2’s mean, the critical region is in the left tail of the distribution.\n",
    "- The vertical dashed line indicates the observed t-statistic from our test.\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "- If the observed t-statistic falls within the shaded rejection region (i.e., to the left of the critical value), we reject the null hypothesis and conclude that there is statistically significant evidence that Group 1 has a lower mean than Group 2.\n",
    "- If the t-statistic falls outside the shaded region, we fail to reject the null hypothesis, meaning the data do not provide strong enough evidence to support the claim that Group 1’s mean is lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "alpha = 0.05\n",
    "\n",
    "x = np.linspace(-4, 4, 1000)\n",
    "y = t.pdf(x, df)\n",
    "\n",
    "# critical t-value for one-tailed test (left tail)\n",
    "t_crit = t.ppf(alpha, df)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(x, y, label=f't-distribution (df={df:.2f})')\n",
    "\n",
    "# shade rejection region (left tail)\n",
    "x_fill = np.linspace(-4, t_crit, 100)\n",
    "# alpha here denotes transparency, not significance level\n",
    "plt.fill_between(x_fill, 0, t.pdf(x_fill, df), color='red', alpha=0.3, label='Rejection region')\n",
    "\n",
    "# mark statistic\n",
    "plt.axvline(t_stat, color='black', linestyle='--', label=f'Observed t-statistic = {t_stat:.2f}')\n",
    "\n",
    "plt.title('One-tailed t-test: t-distribution and Rejection Region')\n",
    "plt.xlabel('t value')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "Since the t-statistic lies well outside the left-tail rejection region (it is positive, not sufficiently negative), and the p-value is greater than our alpha of 0.05, we fail to reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "## Two-tailed t-test\n",
    "\n",
    "We will use the `breast_cancer` dataset for an example. The target is a whether or not a tumor is cancerous. We will examine if there is a difference in the target based of off `mean radius`. More formally:\n",
    "- Do malignant and benign turmors differ in mean radius?\n",
    "\n",
    "In reality, we might reasonably expect malignant tumors to have a larger mean radius than benign ones, based on prior clinical knowledge. However, for the purpose of demonstrating a two-tailed t-test, we proceed as if we had no prior directional hypothesis, and simply test whether there is any difference in mean radius between the two groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_breast_cancer(as_frame=True)\n",
    "df = dataset.frame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "We can formulate the problem as thus:\n",
    "\n",
    "**Hypotheses**\n",
    "- $ H_0: \\mu_1 = \\mu_2 $ (Malignant and benign tumors have the same `mean radius`)\n",
    "- $ H_a: \\mu_1 \\neq \\mu_2 $ (The `mean radius` differs between malignant and benign tumors,)\n",
    "\n",
    "Again, we shall use an alpha value of 0.05 to determine significance.\n",
    "\n",
    "$$ alpha = 0.05 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "Create the test groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_0 = df[df[\"target\"] == 0][\"mean radius\"] # malignant\n",
    "group_1 = df[df[\"target\"] == 1][\"mean radius\"] # benign"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "### Validating assumptions\n",
    "\n",
    "The two-tailed t-test has the same core assumptions as the one-tailed. Again, we shall attempt to validate each one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "#### Independence\n",
    "\n",
    "As stated above, this assumption is reasonably satisfied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "#### Normality\n",
    "\n",
    "Plot the Q-Q plot for each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "stats.probplot(group_0, dist=\"norm\", plot=axs[0])\n",
    "axs[0].set_title(\"Q-Q Plot: Malignant\")\n",
    "\n",
    "stats.probplot(group_1, dist=\"norm\", plot=axs[1])\n",
    "axs[1].set_title(\"Q-Q Benign\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "Normality Observations:\n",
    "\n",
    "- In general, the data points closely follow the 45 degree reference line, indicating approximate normality for both groups.\n",
    "- This pattern is especially pronounced for the benign tumor group.\n",
    "- For the malignant tumor group, there is a slight deviation from the line at the ends, suggesting a mild departure from normality in the tails.\n",
    "\n",
    "Overall, the Q-Q plots suggest that the assumption of normality is reasonably satisfied for both groups, with only minor deviations that are unlikely to substantially impact the validity of the t-test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "#### Homoscedacity\n",
    "\n",
    "The same tests will be performed again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "**Boxplot inspection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.boxplot(column=\"mean radius\", by=\"target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "Boxplot observations:\n",
    "- The boxplots clearly show that the two groups have significantly different variances, with the benign tumors exhibiting a smaller spread in mean radius.\n",
    "- Malignant tumors (class 0) tend to have more outliers, which are generally larger than the group mean, indicating greater variability and occasional extreme values compared to benign tumors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "**Levene's test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "levene_stat, levene_p_stat = levene(group_0, group_1)\n",
    "print(f\"Levene's test statistic: {levene_stat:.4f}\")\n",
    "print(f\"p-value: {levene_p_stat:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "Levene's observations:\n",
    "- A Levene’s test statistic value of 90.48 indicates that the variance differences between the groups are large relative to the variability within each group. This suggests the groups have different variances.\n",
    "- A p-value of < 0.001 is much smaller than our alpha of 0.05, so we reject the null hypothesis of equal variances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "#### Validating Assumptions - Conclusion\n",
    "\n",
    "Considering the above results, the assumptions of independence and normality were verified. However, the assumption of equal variances has been violated, as indicated by both the boxplot inspection and Levene’s test results. Going forward, we will use Welch’s t-test, which is robust to unequal variances, to compare the group means."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "### Hypothesis Testing\n",
    "\n",
    "We shall now perform the two-tailed t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# equal_var=False performs Welch's t-test which is more robust to different population variances \n",
    "result = ttest_ind(group_2, group_1, equal_var=False)\n",
    "t_stat, p_two_tailed, df = result.statistic, result.pvalue, result.df\n",
    "\n",
    "print(f\"t-statistic: {t_stat:.4f}\")\n",
    "print(f\"One-tailed p-value: {p_two_tailed:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {},
   "source": [
    "Considering the above results:\n",
    "- A *t-statistic* value of 26.3161 suggests that the groups means are very far apart. This is strong evidence that there is a difference.\n",
    "- A *p-value* of < 0.0001 is much less than our alpha of 0.05\n",
    "\n",
    "In conclusion, based off of the above two-tailed t-test we **reject** the **null** hypothesis as there is statistically significant evidence to conclude that the `mean radius` differs between malignant and benign tumors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "alpha = 0.05\n",
    "\n",
    "# even though the extreme t-stat, plotting larger than [-5, 5] just looks silly\n",
    "x = np.linspace(-5, 5, 1000)\n",
    "y = t.pdf(x, df)\n",
    "\n",
    "# critical t-value for one-tailed test (left tail)\n",
    "t_crit_low = t.ppf(alpha / 2, df)\n",
    "t_crit_high = t.ppf(1 - alpha / 2, df)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(x, y, label=f't-distribution (df={df:.2f})')\n",
    "\n",
    "# shade left rejection region\n",
    "x_fill_left = np.linspace(-4, t_crit_low, 100)\n",
    "plt.fill_between(x_fill_left, 0, t.pdf(x_fill_left, df), color='red', alpha=0.3, label='Rejection region (left tail)')\n",
    "\n",
    "# shade right rejection region\n",
    "x_fill_right = np.linspace(t_crit_high, 4, 100)\n",
    "plt.fill_between(x_fill_right, 0, t.pdf(x_fill_right, df), color='red', alpha=0.3, label='Rejection region (right tail)')\n",
    "\n",
    "# mark statistic\n",
    "plt.axvline(t_stat, color='black', linestyle='--', label=f'Observed t-statistic = {t_stat:.2f}')\n",
    "\n",
    "plt.title('Two-tailed t-test: t-distribution and Rejection Regions')\n",
    "plt.xlabel('t value')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.legend(loc=\"upper center\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "This graph presents an intersting case where the t-statistic is so extremely large, it is difficult to effectively plot. The uppper rejection region *technically* spans from [t_crit_upper, +infinity], so therefore out t-statistic *does* infact lie within the upper rejection region, therefore showing that we reject the null hypothesis. Re-creating the above plot, for x-values closer to the t-statistic should give us a better view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define x range ±1% around statistic\n",
    "x_min = t_stat * 0.99\n",
    "x_max = t_stat * 1.01\n",
    "x = np.linspace(x_min, x_max, 500)\n",
    "y = t.pdf(x, df)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(x, y, label=f't-distribution (df={df})')\n",
    "\n",
    "# shade rejection region\n",
    "plt.fill_between(x, 0, t.pdf(x, df), color='red', alpha=0.3, label='Rejection region (right tail)')\n",
    "\n",
    "# mark statistic\n",
    "plt.axvline(t_stat, color='black', linestyle='--', label=f'Observed t-statistic = {t_stat:.2f}')\n",
    "\n",
    "plt.title('Right-tailed t-test: Zoomed View Around Observed t-statistic')\n",
    "plt.xlabel('t value')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook explored both one-tailed and two-tailed t-tests as methods to compare group means, and evaluate the statistical significance.\n",
    "\n",
    "- The t-test assumptions independance, normality and homoscedacity (equal variance), were validated. When the equal variance assumption is violated, as shown in the cancer dataset, Welch’s t-test (equal_var=False) provides a more reliable alternative to the Student’s t-test.\n",
    "- Interpreting the t-statistic and p-value together allows us to make informed decisions about rejecting or failing to reject the null hypothesis.\n",
    "\n",
    "Understanding these principles is foundational for more advanced statistical techniques"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
